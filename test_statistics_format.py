#!/usr/bin/env python3
"""Test the updated statistics format"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_statistics_format():
    """Test that statistics format matches user requirements"""
    print("ğŸ§ª TESTING STATISTICS FORMAT")
    print("=" * 50)
    
    try:
        from track_record import TrackRecordManager
        from datetime import datetime
        
        api_key = "b37303668c4be1b78ac35b9e96460458e72b74749814a7d6f44983ac4b432079"
        tracker = TrackRecordManager(api_key)
        metricas = tracker.calcular_metricas_rendimiento()
        
        print("ğŸ“Š Raw metrics:", metricas)
        print()
        
        if "error" in metricas:
            mensaje = f"""ğŸ“Š ESTADÃSTICAS BETGENIUX

ğŸ¯ PRONOSTICOS:
â€¢ Total: 0
â€¢ Pendientes: 0
â€¢ Aciertos: 0
â€¢ Fallos: 0
â€¢ Tasa de Ã©xito: 0.0%


ğŸ“… Actualizado: {datetime.now().strftime('%Y-%m-%d')}"""
            print("âŒ Error case - showing default format:")
        else:
            fallos = metricas['predicciones_resueltas'] - metricas['aciertos']
            mensaje = f"""ğŸ“Š ESTADÃSTICAS BETGENIUX

ğŸ¯ PRONOSTICOS:
â€¢ Total: {metricas['total_predicciones']}
â€¢ Pendientes: {metricas['predicciones_pendientes']}
â€¢ Aciertos: {metricas['aciertos']}
â€¢ Fallos: {fallos}
â€¢ Tasa de Ã©xito: {metricas['tasa_acierto']:.1f}%


ğŸ“… Actualizado: {metricas['fecha_calculo'][:10]}"""
            print("âœ… Success case - showing real data:")
        
        print(mensaje)
        print()
        print("âœ… Statistics format test completed successfully!")
        return True
        
    except Exception as e:
        print(f"âŒ Error testing statistics format: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_statistics_format()
